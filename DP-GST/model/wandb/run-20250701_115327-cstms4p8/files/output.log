Logging to ./model/gst_diffusion/cstms4p8
/home/sunyahui/anaconda3/envs/difusco/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:479: LightningDeprecationWarning: Setting `Trainer(gpus=[0, 3])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[0, 3])` instead.
  f"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed"
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
----------------------------------------------------------------------------------------------------
ResidualGatedGCNModel(
  (nodes_coord_embedding): Linear(in_features=1, out_features=256, bias=False)
  (edge_embed): Sequential(
    (0): Linear(in_features=1, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
  )
  (gcn_layers): ModuleList(
    (0): ResidualGatedGCNLayer(
      (node_feat): NodeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_feat): EdgeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (bn_node): BatchNormNode(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (bn_edge): BatchNormEdge(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): ResidualGatedGCNLayer(
      (node_feat): NodeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_feat): EdgeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (bn_node): BatchNormNode(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (bn_edge): BatchNormEdge(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): ResidualGatedGCNLayer(
      (node_feat): NodeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_feat): EdgeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (bn_node): BatchNormNode(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (bn_edge): BatchNormEdge(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): ResidualGatedGCNLayer(
      (node_feat): NodeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_feat): EdgeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (bn_node): BatchNormNode(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (bn_edge): BatchNormEdge(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (4): ResidualGatedGCNLayer(
      (node_feat): NodeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_feat): EdgeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (bn_node): BatchNormNode(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (bn_edge): BatchNormEdge(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (5): ResidualGatedGCNLayer(
      (node_feat): NodeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_feat): EdgeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (bn_node): BatchNormNode(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (bn_edge): BatchNormEdge(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (6): ResidualGatedGCNLayer(
      (node_feat): NodeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_feat): EdgeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (bn_node): BatchNormNode(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (bn_edge): BatchNormEdge(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (7): ResidualGatedGCNLayer(
      (node_feat): NodeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_feat): EdgeFeatures(
        (Us): Linear(in_features=256, out_features=256, bias=True)
        (Vs): Linear(in_features=256, out_features=256, bias=True)
      )
      (bn_node): BatchNormNode(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (bn_edge): BatchNormEdge(
        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (mlp_edges): MLP(
    (layers): Sequential()
    (output): Linear(in_features=256, out_features=1, bias=True)
    (out): Sequential(
      (0): GroupNorm32(32, 256, eps=1e-05, affine=True)
      (1): ReLU()
      (2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
----------------------------------------------------------------------------------------------------
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Parameters: 2181122
/home/sunyahui/anaconda3/envs/difusco/lib/python3.7/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Training steps: 120000
  | Name  | Type                  | Params
------------------------------------------------
0 | model | ResidualGatedGCNModel | 2.2 M
------------------------------------------------
2.2 M     Trainable params
0         Non-trainable params
2.2 M     Total params
8.724     Total estimated model params size (MB)
/home/sunyahui/anaconda3/envs/difusco/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
/home/sunyahui/anaconda3/envs/difusco/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Sanity Checking: 0it [00:00, ?it/s]Validation dataset size: 64
Sanity Checking DataLoader 0:   0%|                                                                           | 0/2 [00:00<?, ?it/s]error :114.8
Sanity Checking DataLoader 0:  50%|█████████████████████████████████                                 | 1/2 [02:29<02:29, 149.69s/it]error :224.14754098360655
Sanity Checking DataLoader 0: 100%|██████████████████████████████████████████████████████████████████| 2/2 [06:30<00:00, 195.30s/it]metrics:{'val_solved_cost_mean': tensor(333.5460, device='cuda:0')}




































































































































































































































































































Epoch 0:  82%|██████████████████████████████▉       | 6552/8032 [10:39<02:24, 10.24it/s, loss=0.0131, v_num=s4p8, train/loss=0.0162]

Epoch 0: 100%|████████████████████████████████████▊| 8000/8032 [12:59<00:03, 10.26it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.13333333333333333
Epoch 0: 100%|████████████████████████████████████▊| 8001/8032 [13:00<00:03, 10.26it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.0
Epoch 0: 100%|████████████████████████████████████▊| 8002/8032 [13:00<00:02, 10.25it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :2.2545454545454544
Epoch 0: 100%|████████████████████████████████████▊| 8003/8032 [13:00<00:02, 10.25it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.013888888888888888
Epoch 0: 100%|████████████████████████████████████▊| 8004/8032 [13:01<00:02, 10.24it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.5245901639344263
Epoch 0: 100%|████████████████████████████████████▉| 8005/8032 [13:01<00:02, 10.24it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.0
Epoch 0: 100%|████████████████████████████████████▉| 8006/8032 [13:02<00:02, 10.24it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.0
Epoch 0: 100%|████████████████████████████████████▉| 8007/8032 [13:02<00:02, 10.24it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.075
Epoch 0: 100%|████████████████████████████████████▉| 8008/8032 [13:02<00:02, 10.23it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.08771929824561403
Epoch 0: 100%|████████████████████████████████████▉| 8009/8032 [13:02<00:02, 10.23it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.013888888888888888
Epoch 0: 100%|████████████████████████████████████▉| 8010/8032 [13:03<00:02, 10.23it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.4550898203592814
Epoch 0: 100%|████████████████████████████████████▉| 8011/8032 [13:03<00:02, 10.23it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :1.4
Epoch 0: 100%|████████████████████████████████████▉| 8012/8032 [13:03<00:01, 10.22it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.16666666666666666
Epoch 0: 100%|████████████████████████████████████▉| 8013/8032 [13:03<00:01, 10.22it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.20833333333333334
Epoch 0: 100%|████████████████████████████████████▉| 8014/8032 [13:04<00:01, 10.22it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :1.6181818181818182
Epoch 0: 100%|████████████████████████████████████▉| 8015/8032 [13:04<00:01, 10.21it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.3772455089820359
Epoch 0: 100%|████████████████████████████████████▉| 8016/8032 [13:04<00:01, 10.21it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.639344262295082
Epoch 0: 100%|████████████████████████████████████▉| 8017/8032 [13:05<00:01, 10.21it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.4251497005988024
Epoch 0: 100%|████████████████████████████████████▉| 8018/8032 [13:05<00:01, 10.21it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.13333333333333333
Epoch 0: 100%|████████████████████████████████████▉| 8019/8032 [13:05<00:01, 10.20it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.47305389221556887
Epoch 0: 100%|████████████████████████████████████▉| 8020/8032 [13:06<00:01, 10.20it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.027777777777777776
Epoch 0: 100%|████████████████████████████████████▉| 8021/8032 [13:06<00:01, 10.19it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.16666666666666666
Epoch 0: 100%|████████████████████████████████████▉| 8022/8032 [13:07<00:00, 10.19it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.15
Epoch 0: 100%|████████████████████████████████████▉| 8023/8032 [13:07<00:00, 10.19it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.5081967213114754
Epoch 0: 100%|████████████████████████████████████▉| 8024/8032 [13:07<00:00, 10.18it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.2543859649122807
Epoch 0: 100%|████████████████████████████████████▉| 8025/8032 [13:08<00:00, 10.18it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.3652694610778443
Epoch 0: 100%|████████████████████████████████████▉| 8026/8032 [13:08<00:00, 10.18it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.13333333333333333
Epoch 0: 100%|████████████████████████████████████▉| 8027/8032 [13:08<00:00, 10.18it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.7090909090909091
Epoch 0: 100%|████████████████████████████████████▉| 8028/8032 [13:08<00:00, 10.18it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.7272727272727273
Epoch 0: 100%|████████████████████████████████████▉| 8029/8032 [13:09<00:00, 10.17it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.027777777777777776
Epoch 0: 100%|████████████████████████████████████▉| 8030/8032 [13:09<00:00, 10.17it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.5081967213114754
Epoch 0: 100%|████████████████████████████████████▉| 8031/8032 [13:10<00:00, 10.17it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]error :0.027777777777777776
Epoch 0: 100%|█████████████████████████████████████| 8032/8032 [13:10<00:00, 10.16it/s, loss=0.0086, v_num=s4p8, train/loss=0.00483]metrics:{'val_solved_cost_mean': tensor(0.4391, device='cuda:0')}



































































































































































































Epoch 1: 100%|███████▉| 8000/8032 [12:58<00:03, 10.28it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8001/8032 [12:58<00:03, 10.28it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8002/8032 [12:58<00:02, 10.27it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.4
Epoch 1: 100%|███████▉| 8003/8032 [12:59<00:02, 10.27it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.1111111111111111
Epoch 1: 100%|███████▉| 8004/8032 [12:59<00:02, 10.27it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.01639344262295082
Epoch 1: 100%|███████▉| 8005/8032 [12:59<00:02, 10.27it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]
Epoch 1: 100%|███████▉| 8006/8032 [13:00<00:02, 10.26it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8007/8032 [13:00<00:02, 10.26it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8008/8032 [13:00<00:02, 10.26it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8009/8032 [13:00<00:02, 10.26it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.1111111111111111
Epoch 1: 100%|███████▉| 8010/8032 [13:01<00:02, 10.25it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8011/8032 [13:01<00:02, 10.25it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.3090909090909091
Epoch 1: 100%|███████▉| 8012/8032 [13:01<00:01, 10.25it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.1111111111111111
Epoch 1: 100%|███████▉| 8013/8032 [13:01<00:01, 10.25it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]
Epoch 1: 100%|███████▉| 8014/8032 [13:02<00:01, 10.25it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.3090909090909091
Epoch 1: 100%|███████▉| 8015/8032 [13:02<00:01, 10.24it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8016/8032 [13:02<00:01, 10.24it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8017/8032 [13:03<00:01, 10.24it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8018/8032 [13:03<00:01, 10.24it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8019/8032 [13:03<00:01, 10.23it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8020/8032 [13:03<00:01, 10.23it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]
Epoch 1: 100%|███████▉| 8021/8032 [13:04<00:01, 10.23it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.1111111111111111
Epoch 1: 100%|███████▉| 8022/8032 [13:04<00:00, 10.23it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8023/8032 [13:04<00:00, 10.22it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8024/8032 [13:05<00:00, 10.22it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8025/8032 [13:05<00:00, 10.22it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8026/8032 [13:05<00:00, 10.22it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8027/8032 [13:05<00:00, 10.21it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]
Epoch 1: 100%|███████▉| 8028/8032 [13:06<00:00, 10.21it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.41818181818181815
Epoch 1: 100%|███████▉| 8029/8032 [13:06<00:00, 10.21it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.1111111111111111
Epoch 1: 100%|███████▉| 8030/8032 [13:06<00:00, 10.21it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.0
Epoch 1: 100%|███████▉| 8031/8032 [13:07<00:00, 10.20it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]error :0.1111111111111111
Epoch 1: 100%|████████| 8032/8032 [13:07<00:00, 10.20it/s, loss=0.00658, v_num=s4p8, train/loss=0.00686, val_solved_cost_mean=0.439]metrics:{'val_solved_cost_mean': tensor(0.0954, device='cuda:0')}




































































































































































































































































































































































































Epoch 2: 100%|███████▉| 8000/8032 [12:58<00:03, 10.27it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8001/8032 [12:58<00:03, 10.27it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.01639344262295082
Epoch 2: 100%|███████▉| 8002/8032 [12:59<00:02, 10.27it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.2
Epoch 2: 100%|███████▉| 8003/8032 [12:59<00:02, 10.27it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8004/8032 [12:59<00:02, 10.26it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.01639344262295082
Epoch 2: 100%|███████▉| 8005/8032 [13:00<00:02, 10.26it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]
Epoch 2: 100%|███████▉| 8006/8032 [13:00<00:02, 10.26it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8007/8032 [13:00<00:02, 10.25it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8008/8032 [13:01<00:02, 10.25it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8009/8032 [13:01<00:02, 10.25it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8010/8032 [13:01<00:02, 10.25it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8011/8032 [13:01<00:02, 10.25it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.10909090909090909
Epoch 2: 100%|███████▉| 8012/8032 [13:02<00:01, 10.24it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8013/8032 [13:02<00:01, 10.24it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]
Epoch 2: 100%|███████▉| 8014/8032 [13:02<00:01, 10.24it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.03636363636363636
Epoch 2: 100%|███████▉| 8015/8032 [13:02<00:01, 10.24it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8016/8032 [13:03<00:01, 10.23it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8017/8032 [13:03<00:01, 10.23it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8018/8032 [13:03<00:01, 10.23it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8019/8032 [13:04<00:01, 10.23it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8020/8032 [13:04<00:01, 10.23it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8021/8032 [13:04<00:01, 10.22it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]
Epoch 2: 100%|███████▉| 8022/8032 [13:04<00:00, 10.22it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8023/8032 [13:05<00:00, 10.22it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8024/8032 [13:05<00:00, 10.21it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8025/8032 [13:05<00:00, 10.21it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8026/8032 [13:05<00:00, 10.21it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8027/8032 [13:06<00:00, 10.21it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.03636363636363636
Epoch 2: 100%|███████▉| 8028/8032 [13:06<00:00, 10.21it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]
Epoch 2: 100%|███████▉| 8029/8032 [13:06<00:00, 10.20it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8030/8032 [13:07<00:00, 10.20it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|███████▉| 8031/8032 [13:07<00:00, 10.20it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]error :0.0
Epoch 2: 100%|████████| 8032/8032 [13:07<00:00, 10.20it/s, loss=0.0036, v_num=s4p8, train/loss=0.00237, val_solved_cost_mean=0.0954]metrics:{'val_solved_cost_mean': tensor(0.0176, device='cuda:0')}





































































































































































































































































































Epoch 3:  75%|█████▎ | 6047/8032 [09:47<03:12, 10.29it/s, loss=0.00295, v_num=s4p8, train/loss=0.00143, val_solved_cost_mean=0.0176]
/home/sunyahui/anaconda3/envs/difusco/lib/python3.7/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")